{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pitfisher/miem_face_recognition/blob/main/FR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Эксперимент 2***\n",
    "\n",
    "*Сравнение лица с его версиями меньшего разрешения Для каждого из изображений лиц создаются его версии в 10 меньших разрешениях: [1024, 768, 512, 256, 224, 128, 112, 96, 64, 32] Далее исходное изображение сравнивается с полученными версиями. Цель: оценить качество работы модели при получении на вход изображения меньшего разрешения чем то, на котором она предобучена. Результаты:*\n",
    "\n",
    "1. Таблица с дистанциями между исходным и уменьшенным изображениями для каждой персоны в наборе данных\n",
    "2. Графики с ломанными линиями, показывающие зависимость метрики сходства от разрешения входного изображения\n",
    "3. Графики рассеяния значений метрик сходства между исходных изображением и его уменьшенными версиями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_xPg7CuKNTS"
   },
   "outputs": [],
   "source": [
    "!pip install deepface\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kawWam89IW-A"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 14:43:22.647210: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-24 14:43:22.647261: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-24 14:43:22.647276: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-24 14:43:22.651383: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image, ImageOps, ImageDraw\n",
    "from deepface import DeepFace\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RBeapy7oWlBz",
    "outputId": "29abd27e-33e1-44b1-ec33-ee835c10b87c"
   },
   "outputs": [],
   "source": [
    "input_folder = '/tf/data/dataset'\n",
    "\n",
    "resolutions = [1024, 768, 512, 256, 224, 128, 112, 96, 64, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"VGG-Face\",\n",
    "    \"Facenet\",\n",
    "    \"Facenet512\",\n",
    "    \"OpenFace\",\n",
    "    \"DeepFace\",\n",
    "    \"DeepID\",\n",
    "    \"ArcFace\",\n",
    "    \"SFace\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {\n",
    "     \"VGG-Face\": 1.17,\n",
    "    \"Facenet\": 0.8,\n",
    "    \"Facenet512\": 1.04,\n",
    "    \"OpenFace\": 0.55,\n",
    "    \"DeepFace\": 0.64,\n",
    "    \"DeepID\": 0.17,\n",
    "    \"ArcFace\": 1.13,\n",
    "    \"SFace\": 1.055,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_to_square_pil(image_array, face_info, border_pixels=0):\n",
    "    \n",
    "    image = Image.fromarray(image_array)\n",
    "    x, y, w, h = face_info['facial_area']['x'], face_info['facial_area']['y'], face_info['facial_area']['w'], face_info['facial_area']['h']\n",
    "    square_size = max(w, h) + 2 * border_pixels\n",
    "    new_x = max(0, x)\n",
    "    new_y = max(0, y)\n",
    "    cropped_image = image.crop((new_x - (h-w)//2 - border_pixels, new_y - border_pixels, new_x - (h-w)//2 + square_size, new_y + square_size))\n",
    "\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image_pil(image, new_resolution):\n",
    "    resized_img = image.resize(new_resolution, Image.LANCZOS)\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_IyCDVZsYzQe"
   },
   "outputs": [],
   "source": [
    "def save_to_csv(data, columns, filename):\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.to_csv(filename + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2aGBMAE5DusN",
    "outputId": "4e53b2e4-035a-4b5e-c8ea-c35ef188eb6a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3de29faa8c48babafc96d702ba3383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing images with VGG-Face:   0%|          | 0/633 [00:00<?, ?image/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = glob.glob(os.path.join(input_folder, \"**\", \"*.JPG\"), recursive=True)\n",
    "\n",
    "data = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "\n",
    "    for img_path in tqdm(files, desc=f\"Processing images with {model_name}\", unit=\"image\"):\n",
    "\n",
    "        path = img_path.split(os.path.sep)\n",
    "        filename = f'{path[-2]}_{path[-1]}'\n",
    "        ds_name = f'{model_name}_{path[-4]}_{path[-3]}'\n",
    "\n",
    "        try:\n",
    "            face_info = DeepFace.extract_faces(img_path=img_path, detector_backend=\"retinaface\")[0]\n",
    "        except ValueError as e:\n",
    "            print(f\"Face detection failed {img_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        image = Image.open(img_path)\n",
    "        image = ImageOps.exif_transpose(image)\n",
    "        image_array = np.array(image)\n",
    "        \n",
    "        cropped_img = crop_to_square_pil(image_array, face_info)\n",
    "        img1 = np.array(cropped_img)\n",
    "\n",
    "        metrics = [] \n",
    " \n",
    "        for resolution in resolutions:\n",
    "\n",
    "            resized_img = resize_image_pil(cropped_img, (resolution, resolution))\n",
    "            img2 = np.array(resized_img)\n",
    "            start_time = time.perf_counter()\n",
    "\n",
    "            try:\n",
    "                result = DeepFace.verify(img1_path=img1,\n",
    "                                         img2_path=img2,\n",
    "                                         enforce_detection=False,\n",
    "                                         detector_backend=\"retinaface\",\n",
    "                                         model_name=model_name,\n",
    "                                         distance_metric=\"euclidean_l2\"\n",
    "                                         )\n",
    "                end_time = time.perf_counter()\n",
    "                fin_time = end_time - start_time\n",
    "\n",
    "                metrics.append(f'{result[\"distance\"]:.5f}')\n",
    "                metrics.append(f'{fin_time:.5f}')\n",
    "\n",
    "            except ValueError as e:\n",
    "                print(f\"Verification failed {img_path}: {e}\")\n",
    "                metrics.extend([None, None])\n",
    "\n",
    "        if ds_name not in data:\n",
    "            data[ds_name] = []\n",
    "\n",
    "        data[ds_name].append([filename] + metrics)\n",
    "\n",
    "columns = ['name'] + [f\"{res}_{metric}\" for res in resolutions for metric in [\"distance\", \"time\"]]\n",
    "\n",
    "for ds_name, ds in data.items():\n",
    "    save_to_csv(ds, columns, ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNmgxpYpLKiYp/xsabLSw4K",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
