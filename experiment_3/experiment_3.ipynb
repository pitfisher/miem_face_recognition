{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9dc4b17-fe96-4fee-890e-994cd4015526",
   "metadata": {},
   "source": [
    "***Эксперимент 3***\n",
    "\n",
    "*Сравнение изображения лица анфас с изображениями с разных ракурсов Цель: оценить, как разные модели справляются с изображениями повёрнутой головы Гипотеза: если дистанции между изображением лица анфас и изображениями повернутой головы малы, значит модель работает хорошо.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34221d4b-bb14-4149-b14e-a1444bda28ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deepface mediapipe\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3892f965-0252-4c4e-9e3d-eef7c1705c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 11:43:37.850834: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-18 11:43:37.850894: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-18 11:43:37.852777: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-18 11:43:37.970767: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image, ImageOps, ImageDraw\n",
    "from deepface import DeepFace\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import ipyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c584d78-981a-4b83-8e42-469275267812",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/tf/data/testt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac41b76c-560b-4fad-a1ce-bb9f1b30645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"VGG-Face\",\n",
    "    \"Facenet\",\n",
    "    \"Facenet512\",\n",
    "    \"OpenFace\",\n",
    "    \"DeepFace\",\n",
    "    \"DeepID\",\n",
    "    \"ArcFace\",\n",
    "    \"SFace\"\n",
    "]\n",
    "thresholds = {\n",
    "     \"VGG-Face\": 1.17,\n",
    "    \"Facenet\": 0.8,\n",
    "    \"Facenet512\": 1.04,\n",
    "    \"OpenFace\": 0.55,\n",
    "    \"DeepFace\": 0.64,\n",
    "    \"DeepID\": 0.17,\n",
    "    \"ArcFace\": 1.13,\n",
    "    \"SFace\": 1.055,\n",
    "}\n",
    "model_resolutions = {\n",
    "    \"VGG-Face\": (224, 224),\n",
    "    \"Facenet\": (220, 220),\n",
    "    \"Facenet512\": (160, 160),\n",
    "    \"OpenFace\": (96, 96),\n",
    "    \"DeepFace\": (152, 152),\n",
    "    \"DeepID\": (55, 47),\n",
    "    \"ArcFace\": (112, 112),\n",
    "    \"SFace\": (112, 112)\n",
    "}\n",
    "detector_backend = \"retinaface\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae2e88ad-d215-4ae3-b70c-c2fe56a78d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_to_square_pil(image, face_info):\n",
    "\n",
    "    x, y, w, h = face_info['facial_area']['x'], face_info['facial_area']['y'], face_info['facial_area']['w'], face_info['facial_area']['h']\n",
    "\n",
    "    square_size = max(w, h)\n",
    "    new_x = max(0, x)\n",
    "    new_y = max(0, y)\n",
    "    cropped_image = image.crop((new_x - (h-w)//2, new_y, new_x - (h-w)//2 + square_size, new_y + square_size))\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "def resize_image_pil(image, new_resolution):\n",
    "    resized_img = image.resize(new_resolution, Image.LANCZOS)\n",
    "    return resized_img\n",
    "    \n",
    "def save_to_csv(data, columns, filename):\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.to_csv(filename + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b35f13-9e9f-4ded-9a23-a2cdde9dfbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_list = os.listdir(os.path.join(input_folder, f\"center/center/\"))\n",
    "horizontal_positions = [\"45_left\",\"center\",\"45_right\"]\n",
    "vertical_positions = [\"up\",\"center\",\"down\"]\n",
    "\n",
    "for model_name, resolution in model_resolutions.items():\n",
    "    print(f\"model: {model_name}\")\n",
    "    df_results_model = []\n",
    "\n",
    "    for person_name in tqdm(users_list):\n",
    "        person_distances = {\"up\": {\"45_left\": 0, \"center\": 0, \"45_right\": 0},\n",
    "                            \"center\": {\"45_left\": 0, \"center\": 0, \"45_right\": 0},\n",
    "                            \"down\": {\"45_left\": 0, \"center\": 0, \"45_right\": 0}}\n",
    "\n",
    "        image_anfas_no_glasses_path = os.path.join(input_folder, f\"center/center/{person_name}/no_glasses.JPG\")\n",
    "        if not os.path.exists(image_anfas_no_glasses_path):\n",
    "            continue\n",
    "    \n",
    "        image_anfas_no_glasses = Image.open(image_anfas_no_glasses_path)\n",
    "        image_anfas_no_glasses = ImageOps.exif_transpose(image_anfas_no_glasses)\n",
    "        face_info_anfas_no_glasses = DeepFace.extract_faces(img_path=image_anfas_no_glasses_path, detector_backend=detector_backend)\n",
    "        cropped_image_anfas_no_glasses = crop_to_square_pil(image_anfas_no_glasses, face_info_anfas_no_glasses[0])\n",
    "        resized_image_anfas_no_glasses = resize_image_pil(cropped_image_anfas_no_glasses, resolution)\n",
    "        image_anfas_no_glasses = np.array(resized_image_anfas_no_glasses)\n",
    "\n",
    "        image_anfas_glasses_path = os.path.join(input_folder, f\"center/center/{person_name}/glasses.JPG\")\n",
    "        yesGlasses = os.path.exists(image_anfas_glasses_path)\n",
    "\n",
    "        for vertical_position in vertical_positions:\n",
    "            for horizontal_position in horizontal_positions:\n",
    "                if vertical_position == horizontal_position:\n",
    "                    continue\n",
    "                image_current_no_glasses_path = os.path.join(input_folder, f\"{vertical_position}/{horizontal_position}/{person_name}/no_glasses.JPG\")\n",
    "                if not os.path.exists(image_current_no_glasses_path):\n",
    "                    continue\n",
    "                image_current_no_glasses = Image.open(image_current_no_glasses_path)\n",
    "                image_current_no_glasses = ImageOps.exif_transpose(image_current_no_glasses)\n",
    "                face_info_current_no_glasses = DeepFace.extract_faces(img_path=image_current_no_glasses_path, detector_backend=detector_backend)\n",
    "                cropped_image_current_no_glasses = crop_to_square_pil(image_current_no_glasses, face_info_current_no_glasses[0])\n",
    "                resized_image_current_no_glasses = resize_image_pil(cropped_image_current_no_glasses, resolution)\n",
    "                image_current_no_glasses = np.array(resized_image_current_no_glasses)\n",
    "                # display(resized_image_current_no_glasses)\n",
    "\n",
    "                result = DeepFace.verify(\n",
    "                    img1_path=image_anfas_no_glasses,\n",
    "                    img2_path=image_current_no_glasses,\n",
    "                    enforce_detection=False,\n",
    "                    detector_backend=detector_backend,\n",
    "                    model_name=model_name,\n",
    "                    distance_metric=\"euclidean_l2\"\n",
    "                )\n",
    "                # print(f\"real run: comparing {vertical_position}/{horizontal_position}/{person_name}/no_glasses.JPG with center/center/{person_name}/no_glasses.JPG, distance is {result['distance']}\")\n",
    "                person_distances[vertical_position][horizontal_position] = result['distance']\n",
    "\n",
    "                if yesGlasses:\n",
    "                    image_anfas_glasses = Image.open(image_anfas_glasses_path)\n",
    "                    image_anfas_glasses = ImageOps.exif_transpose(image_anfas_glasses)\n",
    "                    face_info_anfas_glasses = DeepFace.extract_faces(img_path=image_anfas_glasses_path, detector_backend=detector_backend)\n",
    "                    cropped_image_anfas_glasses = crop_to_square_pil(image_anfas_glasses, face_info_anfas_glasses[0])\n",
    "                    resized_image_anfas_glasses = resize_image_pil(cropped_image_anfas_glasses, resolution)\n",
    "                    image_anfas_glasses = np.array(resized_image_anfas_glasses)\n",
    "                   \n",
    "                    image_current_glasses_path = os.path.join(input_folder, f\"{vertical_position}/{horizontal_position}/{person_name}/glasses.JPG\")\n",
    "                    if not os.path.exists(image_current_glasses_path):\n",
    "                        continue \n",
    "                    image_current_glasses = Image.open(image_current_glasses_path)\n",
    "                    image_current_glasses = ImageOps.exif_transpose(image_current_glasses)\n",
    "                    face_info_current_glasses = DeepFace.extract_faces(img_path=image_current_glasses_path, detector_backend=detector_backend)\n",
    "                    cropped_image_current_glasses = crop_to_square_pil(image_current_glasses, face_info_current_glasses[0])\n",
    "                    resized_image_current_glasses = resize_image_pil(cropped_image_current_glasses, resolution)\n",
    "                    image_current_glasses = np.array(resized_image_current_glasses)\n",
    "                    # display(resized_image_current_glasses)\n",
    "                   \n",
    "                    result_glasses = DeepFace.verify(\n",
    "                        img1_path=image_anfas_glasses,\n",
    "                        img2_path=image_current_glasses,\n",
    "                        enforce_detection=False,\n",
    "                        detector_backend=detector_backend,\n",
    "                        model_name=model_name,\n",
    "                        distance_metric=\"euclidean_l2\"\n",
    "                    )\n",
    "                    # print(f\"real run: comparing {vertical_position}/{horizontal_position}/{person_name}/glasses.JPG with center/center/{person_name}/glasses.JPG, distance is {result_glasses['distance']}\")\n",
    "                    person_distances[vertical_position][horizontal_position] = result_glasses['distance']\n",
    "                    \n",
    "                    df_results_model.append({\n",
    "                        'model_name': model_name,\n",
    "                        'person_name': person_name,\n",
    "                        'vertical_position': vertical_position,\n",
    "                        'horizontal_position': horizontal_position,\n",
    "                        'distance': result_glasses['distance'],\n",
    "                        'verified': result_glasses['verified'],\n",
    "                        'glasses': 'yes'\n",
    "                    })\n",
    "\n",
    "                df_results_model.append({\n",
    "                    'model_name': model_name,\n",
    "                    'person_name': person_name,\n",
    "                    'vertical_position': vertical_position,\n",
    "                    'horizontal_position': horizontal_position,\n",
    "                    'distance': result['distance'],\n",
    "                    'verified': result['verified'],\n",
    "                    'glasses': 'no'\n",
    "                })\n",
    "    \n",
    "    df_results_model = pd.DataFrame(df_results_model)\n",
    "    df_results_model.to_csv(f\"{model_name}_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403260d-0dc4-4ae2-9a04-72ec20ba9a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
